\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage{tikz}\usetikzlibrary{trees}
\usepackage{commath}

\usepackage{booktabs}
\usepackage{listings}
\lstset{
  language=python,
  basicstyle=\scriptsize,
}
\usetheme{ODK}

\AtBeginSection[]
{
  \begin{frame}<beamer>
    \frametitle{Outline}
    \tableofcontents[currentsection]
  \end{frame}
}

\title[Workpackage 5]{Workpackage 5:\\ High Performance Mathematical Computing}

\author{Cl√©ment Pernet}

\institute[ODK Project review]{First OpenDreamKit Project review}

\date{Brussels, April 26, 2017}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Introduction}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{High performance mathematical computing}

  \begin{block}{Computer algebra}
    Typical computation domains:
    \begin{itemize}
    \item $\mathbb{Z}, \mathbb{Q}$: $\leadsto$ multiprecision integers
    \item $\mathbb{Z}/p\mathbb{Z}, \mathbb{F}_q$: $\leadsto$ machine ints or
      floating point, multiprecision
    \item $K[X], K^{m\times n}$, $K[X]^{m\times n}$ for $K=\mathbb{Z},\mathbb{Q},\mathbb{Z}/p\mathbb{Z}$
    \end{itemize}
  \end{block}

  \begin{block} {High performance computing}
    \begin{itemize}
    \item Decades of development for numerical computations
    \item Still at an early development stage for computer algebra
    \item Specificites: cannot blindly benefit from numerical HPC experience
    \end{itemize}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Goal: delivering high performance to maths users}

\uncover<2->{
  \only<1,2>{
    \begin{block}{Harnessing modern hardware $\leadsto$ parallelisation}
  \begin{itemize}
    \item in-core parallelism (SIMD vectorisation)
    \item multi-core parallelism
    \item distributed computing: clusters, cloud
    \end{itemize}
  \end{block}
  }
  
  \only<3>{
    \begin{block}{Languages}
    \begin{itemize}
    \item Computational Maths software uses high level languages (e.g. Python)
    \item High performance delivered by languages close to the metal (C, assembly)
    \end{itemize}
    $\leadsto$ compilation,  automated optimisation
  \end{block}
  }
  }
  \begin{center}
    \only<1>{\includegraphics[width=0.8\textwidth]{software_stack_3}}

    \only<2>{\includegraphics[width=0.8\textwidth]{software_stack_2}}
    
    \only<3>{\includegraphics[width=0.8\textwidth]{software_stack}}
\end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Goal: delivering high performance to maths users}

%%     \begin{center}
%%     \includegraphics[width=0.8\textwidth]{software_stack}
%%   \end{center}

%%     \pause
%%     \begin{itemize}
%%     \item Improve/Develop parallel features of components first,
%%     \item Expose them through the software stack
%%     \item 
%%     \end{itemize}

%% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%   \frametitle{Introduction}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Main tasks under review for the period}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.4: Singular}
\begin{frame}
  \frametitle{Task 5.4: Singular}
\begin{center}{\Large
    \textbf{Singular}: A computer algebra system for polynomial computations.}
\end{center}

  \begin{itemize}
  \item Already has a generic parallelization framework
  \item Focus on optimising  kernel routines for fine grain parallelism
  \end{itemize}

  \begin{description}
  \item[D5.6:] Quadratic sieving for integer factorization
  \item[D5.7:] Parallelization of matrix fast Fourier Transform
  \end{description}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{D5.6: Quadratic Sieving for integer factorization}

  \begin{block}{Quadratic Sieving for integer factorization}
    \begin{description}
    \item[Problem:]  Factor an integer $n$ into prime factors
    \item[Role:] Crucial in algebraic number theory, arithmetic geometry.
    \item [Earlier status:] no HPC implementation for large instances:
      \begin{itemize}
      \item only fast code for up to 17 digits,
      \item only partial sequential implementation for large numbers
      \end{itemize}
    \end{description}
    \end{block}
\end{frame}

\begin{frame}
  \frametitle{D5.6: Quadratic Sieving for integer factorization}
    \begin{block}{Achievements}
      \begin{itemize}
      \item Completed and debugged implementation of large prime variant
      \item Parallelised sieving component of implementation using OpenMP
      \item Experimented with a parallel implementation of Block Wiedemann algorithm
      \end{itemize}
\end{block}
\begin{block}{Results}

      \begin{itemize}
      \item Now modern, robust, parallel code for numbers in
        17--90 digit range \pause
%      \item Block Wiedemann:  \textbf{SIMD} vs \textbf{thread level}
%        parallelism       \pause
%, $\leadsto$ no faster than existing code
      \item Significantly faster on small multicore machines
      \end{itemize}
\vspace{-1.5em}
      \begin{center}
        \begin{table}
          \caption{Speedup for 4 cores (c/f single core): }
        \begin{tabular}{c|ccccc}
        \toprule
            {Digits} & 50 & 60 & 70 & 80 & 90\\
            \midrule
                {Speedup} & $1.1\times$ & $1.76\times$ & $1.55\times$ & $2.69\times$ & $2.80\times$\\
                \bottomrule
      \end{tabular}
\end{table}
      \end{center}
    \end{block}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{D5.7: Parallelise and assembly optimise FFT}

  \begin{block}    {FFT: Fast Fourier Transform over $\mathbb{Z}/p\mathbb{Z}$}
    \begin{itemize}
    \item Among the top 10 most important algorithms
    \item Key to fast arithmetic (integers, polynomials)
    \item Difficult to optimise: high memory bandwidth requirement
    \end{itemize}
    \begin{description}
    \item[Earlier status:]\
      \begin{itemize}
      \item world leading \textbf{sequential} code in MPIR and FLINT;
      \item no parallel code.
        \end{itemize}
    \end{description}
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{D5.7: Parallelise and assembly optimise FFT}
  \begin{block} {Achievements}
  \begin{itemize}
  \item Parallelised Matrix Fourier implementation using OpenMP
  \item Assembly optimised butterfly operations in MPIR
\end{itemize}
  \end{block}

\begin{block}{Results:}

\begin{itemize}
\item $\approx 15\%$ speedup  on Intel Haswell
\item $\approx 20\%$ speedup on Intel Skylake
\item Significant speedups on multicore machines
\end{itemize}
\end{block}

\vspace{-1em}
\begin{table}
  \caption{Speedup of large integer multiplication on 4/8 cores:}
  \begin{tabular}{cccccccc}
  \toprule
{Digits} & 3M & 10M & 35M & 125M & 700M & 3.3B & 14B\\
\midrule
    {4 cores} & $1.35\times$ & $2.67\times$ & $2.92\times$ & $2.92\times$ & $3.01\times$ & $2.95\times$ & $3.32\times$ \\
{8 cores} & $1.35\times$ & $3.56\times$ & $4.22\times$ & $4.36\times$ & $4.50\times$ & $4.31\times$ & $5.49\times$\\
\bottomrule
\end{tabular}
\end{table}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.5: MPIR}
\begin{frame}
  \frametitle{Task 5.5: MPIR}
\begin{center}
  {\Large  \textbf{MPIR} : a library for big integer arithmetic}
\end{center}
\begin{itemize}
  \item Bignum operations: fundamental across all of computer algebra
  \end{itemize}

  \begin{block}
    {D5.5: Assembly superoptimisation}
    \begin{itemize}
    \item MPIR contains assembly language routines for bignum operations
    \\ $\leadsto$ hand optimised for every new microprocessor architecture
    \\ $\leadsto \approx 3-6$ months of work for each architecture
    \item Superoptimisation: rearranges instructions to get optimal
      ordering
    \end{itemize}

    \begin{description}
      \item[Earlier status:]\
        \begin{itemize}
        \item No assembly code for recent ($> 2012$) Intel and AMD chips (Bulldozer,
          Haswell, Skylake, \dots)
        \end{itemize}
            \end{description}



    \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}

\frametitle{D5.5: Assembly superoptimisation}

\begin{block} {Achievements}
\begin{itemize}
\item A new assembly superoptimiser supporting recent instruction sets%, including AVX
\item Superoptimised handwritten assembly code for Haswell and Skylake
\item Hand picked faster assembly code for Bulldozer from existing implementations
\end{itemize}
\end{block}
\begin{block}
  {Results:}
\begin{itemize}
\item Sped up basic arithmetic operations for Bulldozer, Skylake and Haswell
\item Noticeable speedups for bignum arithmetic for all size ranges
\end{itemize}
\end{block}


%% \begin{table}
%% \caption{Speedups for bignum operations}
  \begin{tabular}{cccccccc}
  \toprule
{Op} & \mbox{Mul (s)} & \mbox{Mul (m)} & \mbox{Mul (b)} & \mbox{GCD (s)} & \mbox{GCD (m)} & \mbox{GCD (b)} \\
\midrule
{Haswell} & $1.18\times$ & $1.27\times$ & $1.29\times$ & $0.72\times$ & $1.45\times$ & $1.27\times$\\
{Skylake} & $1.15\times$ & $1.20\times$ & $1.22\times$ & $0.84\times$ & $1.65\times$ & $1.32\times$ \\
\bottomrule
\end{tabular}
%\end{table}

s $= 512$ bits, m $= 8192$ bits, big $= 100$K bits

\end{frame}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}[fragile]

%% \frametitle{D5.5: Assembly superoptimisation}


%% \begin{table}
%% \caption{Speedups for bignum operations}
%%   \begin{tabular}{cccccccc}
%%   \toprule
%% {Op} & \mbox{Mul (s)} & \mbox{Mul (m)} & \mbox{Mul (b)} & \mbox{GCD (s)} & \mbox{GCD (m)} & \mbox{GCD (b)} \\
%% \midrule
%% {Haswell} & $1.18\times$ & $1.27\times$ & $1.29\times$ & $0.72\times$ & $1.45\times$ & $1.27\times$\\
%% {Skylake} & $1.15\times$ & $1.20\times$ & $1.22\times$ & $0.84\times$ & $1.65\times$ & $1.32\times$ \\
%% \bottomrule
%% \end{tabular}
%% \end{table}

%% s $= 512$ bits, m $= 8192$ bits, big $= 100$K bits

%% No substantial speedups were found for the older, less sophisticated Bulldozer over existing assembly routines.

%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.6: Combinatorics}
\begin{frame}[fragile]
  \frametitle{Task 5.6: Combinatorics}
%\begin{frame}[fragile]{Today: Map/Reduce of RESets}

  \begin{center}
    {%
      %      \begin{minipage}{9cm}
      \Large\bf
        Perform a {\color{red}map/reduce} on huge % a very large set
         {\color{blue}recursive} datasets.
 %     \end{minipage}
    }
  \end{center}
  \begin{block}{Large range of intensive applications in combinatorics:}
  \begin{itemize}
%  \item Compute the cardinality, or more generally any kind of generating series
  \item Test a conjecture: i.e. find an element of $S$ satisfying a specific
    property %or check that all of them do
  \item Count/list the elements of $S$ having this property
  \end{itemize}
\end{block}

  \pause
  \begin{block}{Specificities of combinatorics:}
  \begin{itemize}
  \item Sets often \emph{don't fit in the computer's} memory / disks
    and are enumerated \textbf{on the fly} (example of value: $10^{17}$~bytes).
  \item \textbf{Embarassingly parallel}, if the set is flat (a list, a file, stored on a
    disk).
  \item Recursive data-structures may be \textbf{heavily unbalanced}
    
  \end{itemize}
\end{block}
\end{frame}



\begin{frame}[fragile]{A Challenge: The tree of numerical semigroups}
\newcommand{\sgnode}[1]{{\bf \left<#1\right>}}
\newcommand{\gr}[1]{{\color{gray} #1}}
%Extremely unbalanced.
\[\tiny
\begin{tikzpicture}[baseline={([yshift=-5cm]current bounding box.north)},
  scale=0.7,
  level distance=1.5cm, 
  inner sep=2mm,
  level/.style={sibling distance=1.55cm}]
    \node {$\sgnode{1}$}
    child {node {$\sgnode{2,3}$}
      child [sibling distance=4.5cm] {node {$\sgnode{3,4,5}$}
        child {node {$\sgnode{4,5,6,7}$}
          child [sibling distance=2cm]{node {$\sgnode{5,6,7,8,9}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [left] {4}}
          child [sibling distance=1.9cm]{node {$\sgnode{\gr 4,6,7,9}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [left] {5}}
          child {node {$\sgnode{\gr 4,\gr 5,7}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [right] {6}}
          child {node {$\sgnode{\gr 4,\gr 5,\gr 6}$}
            edge from parent node [right] {7}}
          edge from parent node [left] {3}
        }
        child{{} edge from parent[draw=none]}
        child{{} edge from parent[draw=none]}
        child {node {$\sgnode{\gr 3,5,7}$}
          child {node {$\sgnode{\gr 3,7,8}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [left] {5}}
          child {node {$\sgnode{\gr 3,\gr 5}$} edge from parent node [right] {7}}
          edge from parent node [left] {4}
        }
        child {node {$\sgnode{\gr 3,\gr 4}$}
          edge from parent node [right] {5}
        }
        edge from parent node [left] {2}
      }
      child [sibling distance=4.5cm] {node {$\sgnode{\gr2,5}$}
        child {node {$\sgnode{\gr2,7}$}
          child {node {$\sgnode{\gr2,9}$}
            child[sibling distance=0.5cm] {node {$\dots$} edge from parent}
            edge from parent node [right] {7}
          }
          edge from parent node [right] {5}
        }
        edge from parent node [right] {3}
      }
      edge from parent node [left] {1}
    }
   ;
  \end{tikzpicture}
\]
\pause
Need for
\begin{itemize}
\item an \textbf{efficient load balancing algorithm}.
\item a high level task parallelization framework. 
\end{itemize}
\end{frame}



%% \begin{frame}{Work-Stealing System Architecture}
%%   Work stealing algorithm (Leiserson-Blumofe / Cilk):

%% \[\hspace{-0.7cm}\includegraphics[width=12.5cm]{scheme.pdf}\]
%% \end{frame}

\begin{frame}{Work-Stealing System Architecture}
  
  \begin{block}{A Python implementation}
    \begin{itemize}
    \item Work stealing algorithm (Leiserson-Blumofe / Cilk)
    \item Easy to use, easy to call from SageMath
    \item Already, a dozen  use cases
    \item Scale well with the number of CPU cores
    \item Reasonably efficient (knowing that this is Python code).
    \end{itemize}
  \end{block}

  \begin{center}
      \begin{tabular}{c|cccc}
    \toprule
    \# processors & 1 & 2 & 4 & 8\\
    \midrule
    Time (s) & 250 & 161 & 103 & 87
    \bottomrule
  \end{tabular}
  \end{center}

  \begin{block}{References}
    {\footnotesize
      \begin{itemize}  \item Trac Ticket $13580$ \url{http://trac.sagemath.org/ticket/13580}
%    \bigskip
      \item \textit{Exploring the Tree of Numerical Semigroups} J. Fromentin
        and F. Hivert %\url{https://hal.inria.fr/UNIV-ROUEN/hal-00823339v3}
      \end{itemize}
      }
  \end{block}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.7: Pythran}
\begin{frame}
  \frametitle{Task 5.7: Pythran}
  \begin{center}
    {\Large \textbf{Pythran}: a NumPy-centric Python to C compiler}
  \end{center}
  \begin{columns}
    \begin{column}
      {.48\textwidth }
          \includegraphics[width=\textwidth]{software_stack}
    \end{column}
    \begin{column}
      {.48\textwidth }
  \begin{itemize}
  \item Many high level VREs rely on the Python language
  \item High performance is most often achieved  by the C language\pause
  \item Python to C compilers: 
    \begin{description}
    \item[Cython:] general purpose
    \item[Pythran:] narrower scope, better at optimising Numpy code (Linear algebra)
    \end{description}
  \end{itemize}
    \end{column}
  \end{columns}
\pause
  \begin{center}
    \textbf{Goal: Implement the convergence}

    \begin{description}
      \item[D5.4] Improve Pythran typing system
      \item[D5.2] Make Cython use Pythran backend to optimise Numpy code
    \end{description}
  \end{center}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{D5.2: Make Cython use Pythran backend for NumPy code}

  \begin{center}
    \includegraphics[width=.7\textwidth]{float_graph}\\
  \end{center}
  \begin{lstlisting}
import numpy
cimport numpy
def float_comp (numpy.ndarray[numpy.float_t, ndim=1] a,
                 numpy.ndarray[numpy.float_t, ndim=1] b):
     return numpy.sum(numpy.sqrt(a*a+b*b))
\end{lstlisting}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{D5.2: Make Cython use Pythran backend for NumPy code}

  \begin{center}
    \includegraphics[width=.7\textwidth]{harris_graph}
  \end{center}
\vspace{-1em}
  \begin{lstlisting}[basicstyle=\tiny]
def harris(numpy.ndarray[numpy.float_t, ndim=2] I):
  cdef int m = I.shape[0]
  cdef int n = I.shape[1]
  cdef numpy.ndarray[numpy.float_t,ndim=2] dx = (I[1:,:] - I[:m-1,:])[:,1:]
  cdef numpy.ndarray[numpy.float_t,ndim=2] dy = (I[:,1:] - I[:,:n-1])[1:,:]
  cdef numpy.ndarray[numpy.float_t, ndim=2] A = dx * dx
  cdef numpy.ndarray[numpy.float_t, ndim=2] B = dy * dy
  cdef numpy.ndarray[numpy.float_t, ndim=2] C = dx * dy
  cdef numpy.ndarray[numpy.float_t, ndim=2] tr = A + B
  cdef numpy.ndarray[numpy.float_t, ndim=2] det = A * B - C * C
  return det - tr * tr
\end{lstlisting}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \begin{frame}
%%       \frametitle{D5.4: Improve Pythran typing system}
%% \end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Task 5.8: SunGridEngine in JupyterHub}
\begin{frame}
  \frametitle{Task 5.8: SunGridEngine integration in JupyterHub}
  \begin{block}{Access to big compute}
   \begin{itemize}
   \item Traditional access to supercomputers is difficult
   \item Notebooks are easy but run on laptops or desktops
   \item We need a way to connect notebooks to supercomputers
   \end{itemize}
  \end{block}
  \begin{block}{Sun Grid Engine}
    A job scheduler for Academic HPC Clusters
    \begin{itemize}
    \item Controls how resources are allocated to researchers
    \item One of the most popular schedulers
    \end{itemize}
  \end{block}

  \begin{block}{Achievements: D5.3}
  \begin{itemize}
  \item Developed software to run Jupyter notebooks on supercomputers
  \item Users don't need to know details. They just log in.
  \item Demonstration install at University of Sheffield
  \end{itemize}
  \end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Progress report on other tasks}
\begin{frame}
  \frametitle{Progress report on other tasks}

  \begin{block}{T5.1: PARI}
    \begin{itemize}
    \item Generic parallelization engine is now mature, released (D5.10, due M24)
    \end{itemize}
  \end{block}
  \begin{block}{T5.2: GAP}
    \begin{itemize}
    \item 6 releases were published integrating contributions of D3.11 and D5.15
    \item Build system refactoring for integration of HPC GAP
    \end{itemize}
  \end{block}
  \begin{block}{T5.3: LinBox}
    \begin{itemize}
    \item Algorithmic advances (5  articles) on linear algebra and
      verified computing
    \item Software releases and integration into SageMath
    \end{itemize}
  \end{block}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{WP5 highlights}
  \begin{description}
  \item[Sites involved:] UPSud, CNRS, UJF, UNIKL, USFD, USTAN, Logilab
  \item[Workforce:] 49.58 PM (consumed) / 200 PM (total)
  \item[Delivered:] 7 deliverables
  \end{description}

  \begin{itemize}
  \item Optimized parallel kernels: FFT, factorization, bignum arithmetic.
  \item New assembly superoptimizer supporting last generation CPUs
  \item Workstealing based task parallelization for combinatorics exploration
  \item Cython can use Pythran backend to compile Numpy Code
  \item Jupyter can be run on Cluster nodes using SunGridEngine scheduler
  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Task 5.1: Pari}
%% \begin{frame}
%%   \frametitle{Task 5.1: Pari}
%% \end{frame}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Task 5.2: GAP}
%% \begin{frame}
%%   \frametitle{Task 5.1: GAP}
%% \end{frame}
%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \subsection{Task 5.3: LinBox}
%% \begin{frame}
%%   \frametitle{Task 5.3: LinBox}
%% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
